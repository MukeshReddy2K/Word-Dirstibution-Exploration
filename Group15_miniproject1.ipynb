{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "626e2ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mukes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mukes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize.casual import TweetTokenizer, casual_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2257044a",
   "metadata": {},
   "source": [
    "# Corpus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bd98883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Corpus1\\\\pg11774.txt', 'Corpus1\\\\pg16320.txt', 'Corpus1\\\\pg17374.txt', 'Corpus1\\\\pg1903.txt', 'Corpus1\\\\pg26841.txt', 'Corpus1\\\\pg27957.txt', 'Corpus1\\\\pg28409.txt', 'Corpus1\\\\pg29364.txt', 'Corpus1\\\\pg29499.txt', 'Corpus1\\\\pg33331.txt', 'Corpus1\\\\pg34463.txt', 'Corpus1\\\\pg34823.txt', 'Corpus1\\\\pg4359.txt', 'Corpus1\\\\pg44052.txt', 'Corpus1\\\\pg44274.txt', 'Corpus1\\\\pg46499.txt', 'Corpus1\\\\pg52460.txt', 'Corpus1\\\\pg55099.txt', 'Corpus1\\\\pg59042.txt', 'Corpus1\\\\pg60029.txt', 'Corpus1\\\\pg6716.txt', 'Corpus1\\\\pg68369.txt', 'Corpus1\\\\pg70377.txt', 'Corpus1\\\\pg88.txt']\n"
     ]
    }
   ],
   "source": [
    "corpus1_dir = 'Corpus1'\n",
    "\n",
    "text_files = []\n",
    "\n",
    "for filename in os.listdir(str(os.getcwd())+'/'+corpus1_dir+'/'):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(corpus1_dir, filename)\n",
    "\n",
    "        text_files.append(file_path)\n",
    "\n",
    "\n",
    "print(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6d0fa733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words():\n",
    "    lst = []\n",
    "    for file_path in text_files:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            words = word_tokenize(text)\n",
    "            words = [word.lower() for word in words if word.isalnum()]\n",
    "            lst.extend(words)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "96a1b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_words(lst):\n",
    "    word_counter = Counter()\n",
    "    word_counter.update(lst)\n",
    "    return word_counter\n",
    "\n",
    "def most_common_bigrams(lst):\n",
    "    bigram_counter = Counter()\n",
    "    bi_grams = list(ngrams(lst, 2))\n",
    "    bigram_counter.update(bi_grams)\n",
    "    return bigram_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a27fc598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Most Common Words in Corpus 1:\n",
      "('the', 99996)\n",
      "('of', 64773)\n",
      "('and', 38888)\n",
      "('to', 35795)\n",
      "('in', 32331)\n",
      "('a', 27181)\n",
      "('that', 16991)\n",
      "('is', 16736)\n",
      "('it', 13464)\n",
      "('for', 12513)\n",
      "('as', 11396)\n",
      "('be', 10413)\n",
      "('was', 9556)\n",
      "('by', 9094)\n",
      "('this', 8814)\n",
      "('on', 8691)\n",
      "('or', 8154)\n",
      "('with', 8104)\n",
      "('not', 7811)\n",
      "('which', 7709)\n",
      "('are', 7393)\n",
      "('at', 7275)\n",
      "('he', 6846)\n",
      "('have', 6258)\n",
      "('i', 5677)\n",
      "('from', 5599)\n",
      "('money', 5484)\n",
      "('his', 5436)\n",
      "('but', 5303)\n",
      "('all', 5244)\n"
     ]
    }
   ],
   "source": [
    "tokenized_words_corpus1 = tokenize_words()\n",
    "\n",
    "# Get the 30 most common words\n",
    "top_30_words = most_common_words(tokenized_words_corpus1).most_common(30)\n",
    "\n",
    "# Print the 30 most common words\n",
    "print(\"30 Most Common Words in Corpus 1:\")\n",
    "for word in top_30_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "585f3b03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Most Common Words in Corpus 1:\n",
      "('the', 99996)\n",
      "('of', 64773)\n",
      "('and', 38888)\n",
      "('to', 35795)\n",
      "('in', 32331)\n",
      "('a', 27181)\n",
      "('that', 16991)\n",
      "('is', 16736)\n",
      "('it', 13464)\n",
      "('for', 12513)\n",
      "('as', 11396)\n",
      "('be', 10413)\n",
      "('was', 9556)\n",
      "('by', 9094)\n",
      "('this', 8814)\n",
      "('on', 8691)\n",
      "('or', 8154)\n",
      "('with', 8104)\n",
      "('not', 7811)\n",
      "('which', 7709)\n",
      "('are', 7393)\n",
      "('at', 7275)\n",
      "('he', 6846)\n",
      "('have', 6258)\n",
      "('i', 5677)\n",
      "('from', 5599)\n",
      "('money', 5484)\n",
      "('his', 5436)\n",
      "('but', 5303)\n",
      "('all', 5244)\n",
      "('they', 4806)\n",
      "('you', 4519)\n",
      "('their', 4256)\n",
      "('had', 4190)\n",
      "('would', 4190)\n",
      "('has', 4166)\n",
      "('an', 4148)\n",
      "('we', 4139)\n",
      "('will', 3891)\n",
      "('bank', 3803)\n",
      "('one', 3796)\n",
      "('if', 3778)\n",
      "('any', 3712)\n",
      "('were', 3699)\n",
      "('its', 3683)\n",
      "('4', 3674)\n",
      "('been', 3647)\n",
      "('other', 3481)\n",
      "('there', 3314)\n",
      "('no', 3310)\n",
      "('so', 3186)\n",
      "('new', 3071)\n",
      "('value', 2975)\n",
      "('may', 2944)\n",
      "('est', 2881)\n",
      "('can', 2808)\n",
      "('than', 2797)\n",
      "('our', 2789)\n",
      "('who', 2784)\n",
      "('these', 2773)\n",
      "('when', 2747)\n",
      "('more', 2716)\n",
      "('gold', 2711)\n",
      "('stock', 2643)\n",
      "('them', 2483)\n",
      "('only', 2357)\n",
      "('great', 2344)\n",
      "('business', 2319)\n",
      "('such', 2310)\n",
      "('do', 2283)\n",
      "('time', 2282)\n",
      "('banks', 2204)\n",
      "('exchange', 2197)\n",
      "('project', 2169)\n",
      "('states', 2127)\n",
      "('made', 2061)\n",
      "('out', 2024)\n",
      "('very', 1963)\n",
      "('should', 1947)\n",
      "('country', 1940)\n",
      "('upon', 1931)\n",
      "('market', 1916)\n",
      "('some', 1915)\n",
      "('what', 1903)\n",
      "('york', 1768)\n",
      "('work', 1753)\n",
      "('per', 1729)\n",
      "('much', 1697)\n",
      "('up', 1680)\n",
      "('credit', 1672)\n",
      "('into', 1663)\n",
      "('about', 1654)\n",
      "('united', 1650)\n",
      "('same', 1612)\n",
      "('years', 1560)\n",
      "('most', 1552)\n",
      "('now', 1510)\n",
      "('must', 1480)\n",
      "('then', 1458)\n",
      "('my', 1438)\n"
     ]
    }
   ],
   "source": [
    "# Get the 100 most common words\n",
    "top_100_words = most_common_words(tokenized_words_corpus1).most_common(100)\n",
    "\n",
    "# Print the 100 most common words\n",
    "print(\"100 Most Common Words in Corpus 1:\")\n",
    "for word in top_100_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c5304746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Common Words in Corpus 1:\n",
      "('the', 99996)\n",
      "('of', 64773)\n",
      "('and', 38888)\n",
      "('to', 35795)\n",
      "('in', 32331)\n",
      "('a', 27181)\n",
      "('that', 16991)\n",
      "('is', 16736)\n",
      "('it', 13464)\n",
      "('for', 12513)\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common words\n",
    "top_10_words = most_common_words(tokenized_words_corpus1).most_common(10)\n",
    "\n",
    "# Print the 10 most common words\n",
    "print(\"10 Most Common Words in Corpus 1:\")\n",
    "for word in top_10_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd08dc",
   "metadata": {},
   "source": [
    "### Q2 Repeat exercise 1 above but now do it for n-grams with n = 2 (bi-grams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3ec04997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Most Common bi-grams in Corpus 1:\n",
      "(('of', 'the'), 17240)\n",
      "(('in', 'the'), 8638)\n",
      "(('to', 'the'), 5524)\n",
      "(('and', 'the'), 3683)\n",
      "(('on', 'the'), 3462)\n",
      "(('for', 'the'), 3022)\n",
      "(('it', 'is'), 2975)\n",
      "(('that', 'the'), 2877)\n",
      "(('4', 'est'), 2877)\n",
      "(('to', 'be'), 2632)\n",
      "(('by', 'the'), 2620)\n",
      "(('with', 'the'), 2285)\n",
      "(('of', 'a'), 2127)\n",
      "(('at', 'the'), 1924)\n",
      "(('new', 'york'), 1752)\n",
      "(('from', 'the'), 1648)\n",
      "(('of', 'this'), 1599)\n",
      "(('united', 'states'), 1571)\n",
      "(('in', 'a'), 1492)\n",
      "(('the', 'bank'), 1424)\n",
      "(('of', 'money'), 1394)\n",
      "(('is', 'a'), 1393)\n",
      "(('as', 'a'), 1391)\n",
      "(('the', 'same'), 1383)\n",
      "(('it', 'was'), 1309)\n",
      "(('as', 'the'), 1279)\n",
      "(('the', 'united'), 1275)\n",
      "(('is', 'the'), 1227)\n",
      "(('all', 'the'), 1209)\n",
      "(('have', 'been'), 1148)\n"
     ]
    }
   ],
   "source": [
    "# Get the 30 most common words for ngram with n = 2\n",
    "top_30_words = most_common_bigrams(tokenized_words_corpus1).most_common(30)\n",
    "\n",
    "# Print the 30 most common words\n",
    "print(\"30 Most Common bi-grams in Corpus 1:\")\n",
    "for word in top_30_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "88e7ef63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Most Common bi-grams in Corpus 1:\n",
      "(('of', 'the'), 17240)\n",
      "(('in', 'the'), 8638)\n",
      "(('to', 'the'), 5524)\n",
      "(('and', 'the'), 3683)\n",
      "(('on', 'the'), 3462)\n",
      "(('for', 'the'), 3022)\n",
      "(('it', 'is'), 2975)\n",
      "(('that', 'the'), 2877)\n",
      "(('4', 'est'), 2877)\n",
      "(('to', 'be'), 2632)\n",
      "(('by', 'the'), 2620)\n",
      "(('with', 'the'), 2285)\n",
      "(('of', 'a'), 2127)\n",
      "(('at', 'the'), 1924)\n",
      "(('new', 'york'), 1752)\n",
      "(('from', 'the'), 1648)\n",
      "(('of', 'this'), 1599)\n",
      "(('united', 'states'), 1571)\n",
      "(('in', 'a'), 1492)\n",
      "(('the', 'bank'), 1424)\n",
      "(('of', 'money'), 1394)\n",
      "(('is', 'a'), 1393)\n",
      "(('as', 'a'), 1391)\n",
      "(('the', 'same'), 1383)\n",
      "(('it', 'was'), 1309)\n",
      "(('as', 'the'), 1279)\n",
      "(('the', 'united'), 1275)\n",
      "(('is', 'the'), 1227)\n",
      "(('all', 'the'), 1209)\n",
      "(('have', 'been'), 1148)\n",
      "(('value', 'of'), 1141)\n",
      "(('per', 'cent'), 1084)\n",
      "(('would', 'be'), 1077)\n",
      "(('there', 'is'), 1064)\n",
      "(('the', 'stock'), 1062)\n",
      "(('has', 'been'), 1045)\n",
      "(('in', 'this'), 1039)\n",
      "(('may', 'be'), 1025)\n",
      "(('will', 'be'), 994)\n",
      "(('to', 'a'), 899)\n",
      "(('the', 'country'), 878)\n",
      "(('is', 'not'), 875)\n",
      "(('one', 'of'), 867)\n",
      "(('of', 'his'), 856)\n",
      "(('for', 'a'), 852)\n",
      "(('stock', 'exchange'), 832)\n",
      "(('and', 'that'), 822)\n",
      "(('the', 'money'), 816)\n",
      "(('the', 'value'), 808)\n",
      "(('part', 'of'), 795)\n",
      "(('he', 'was'), 794)\n",
      "(('the', 'project'), 779)\n",
      "(('and', 'in'), 778)\n",
      "(('wall', 'street'), 762)\n",
      "(('had', 'been'), 761)\n",
      "(('they', 'are'), 759)\n",
      "(('the', 'new'), 759)\n",
      "(('do', 'not'), 755)\n",
      "(('project', 'gutenberg'), 754)\n",
      "(('out', 'of'), 750)\n",
      "(('amount', 'of'), 742)\n",
      "(('bank', 'of'), 737)\n",
      "(('that', 'it'), 737)\n",
      "(('the', 'market'), 731)\n",
      "(('of', 'their'), 716)\n",
      "(('we', 'have'), 709)\n",
      "(('which', 'the'), 709)\n",
      "(('should', 'be'), 693)\n",
      "(('of', 'gold'), 692)\n",
      "(('that', 'is'), 679)\n",
      "(('as', 'to'), 679)\n",
      "(('the', 'public'), 674)\n",
      "(('to', 'make'), 669)\n",
      "(('not', 'be'), 658)\n",
      "(('was', 'a'), 658)\n",
      "(('when', 'the'), 655)\n",
      "(('of', 'our'), 655)\n",
      "(('the', 'other'), 654)\n",
      "(('and', 'a'), 642)\n",
      "(('the', 'world'), 641)\n",
      "(('i', 'have'), 641)\n",
      "(('of', 'these'), 638)\n",
      "(('can', 'not'), 634)\n",
      "(('if', 'the'), 634)\n",
      "(('the', 'first'), 623)\n",
      "(('the', 'great'), 616)\n",
      "(('the', 'state'), 604)\n",
      "(('with', 'a'), 598)\n",
      "(('in', 'which'), 597)\n",
      "(('of', 'its'), 595)\n",
      "(('more', 'than'), 594)\n",
      "(('at', 'a'), 589)\n",
      "(('of', 'all'), 589)\n",
      "(('was', 'the'), 589)\n",
      "(('but', 'the'), 585)\n",
      "(('the', 'most'), 581)\n",
      "(('if', 'you'), 565)\n",
      "(('the', 'banks'), 565)\n",
      "(('can', 'be'), 563)\n",
      "(('that', 'he'), 562)\n"
     ]
    }
   ],
   "source": [
    "# Get the 100 most common words for ngram with n = 2\n",
    "top_100_words = most_common_bigrams(tokenized_words_corpus1).most_common(100)\n",
    "\n",
    "# Print the 100 most common words\n",
    "print(\"100 Most Common bi-grams in Corpus 1:\")\n",
    "for word in top_100_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "644032d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Common bi-grams in Corpus 1:\n",
      "(('of', 'the'), 17240)\n",
      "(('in', 'the'), 8638)\n",
      "(('to', 'the'), 5524)\n",
      "(('and', 'the'), 3683)\n",
      "(('on', 'the'), 3462)\n",
      "(('for', 'the'), 3022)\n",
      "(('it', 'is'), 2975)\n",
      "(('that', 'the'), 2877)\n",
      "(('4', 'est'), 2877)\n",
      "(('to', 'be'), 2632)\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common words for ngram with n = 2\n",
    "top_10_words = most_common_bigrams(tokenized_words_corpus1).most_common(10)\n",
    "\n",
    "# Print the 10 most common words\n",
    "print(\"10 Most Common bi-grams in Corpus 1:\")\n",
    "for word in top_10_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e441873",
   "metadata": {},
   "source": [
    "### Q3 Find a stop word list. Then remove all words in that stop list and repeat exercise 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a1543065",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "not_stop_words_list = [word for word in tokenized_words_corpus1 if word not in stop_words]\n",
    "\n",
    "def stop_word_common_words(not_stop_words_list):\n",
    "    word_counter = Counter()\n",
    "    word_counter.update(not_stop_words_list)\n",
    "    return word_counter\n",
    "\n",
    "def stop_word_common_bigrams(not_stop_words_list):\n",
    "    bigram_counter = Counter()\n",
    "    bi_grams = list(ngrams(not_stop_words_list, 2))\n",
    "    bigram_counter.update(bi_grams)\n",
    "    return bigram_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d0aa916f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all the stopwords in corpus1 {'about', 'these', 'while', 'd', 'hasn', 'between', 'by', 'ourselves', 'you', 'own', 'isn', 'was', 'yourselves', 'other', 'their', 'our', 'why', 'for', 'further', 'so', 'during', 'before', 'myself', 'herself', 'which', 'my', 'or', 'had', 've', 'having', 'this', 'be', 'whom', 'each', 'm', 'yourself', 'more', 'have', 'out', 'on', 'haven', 'too', 'over', 'its', 'in', 'any', 'wouldn', 'wasn', 'just', 'been', 'has', 'her', 'y', 'now', 'most', 'itself', 'as', 'once', 'won', 'your', 'a', 'few', 'does', 'above', 'yours', 'they', 'who', 'the', 'both', 'only', 'to', 'should', 'i', 'them', 'until', 'when', 'what', 'some', 'his', 'being', 'couldn', 'll', 'with', 'such', 'all', 'theirs', 'can', 'he', 'is', 'under', 'don', 'after', 'here', 'than', 'did', 'o', 't', 'an', 'from', 'himself', 'doing', 'of', 'themselves', 'am', 'because', 'where', 'nor', 'against', 'him', 'then', 'up', 'will', 'same', 's', 'but', 'do', 'those', 'it', 're', 'are', 'there', 'if', 'very', 'that', 'we', 'were', 'and', 'she', 'through', 'me', 'down', 'off', 'didn', 'how', 'into', 'no', 'below', 'doesn', 'again', 'not', 'at', 'ours'}\n",
      "142\n"
     ]
    }
   ],
   "source": [
    "# list of all the stop words in corpus 1\n",
    "stop_words_list = [word for word in tokenized_words_corpus1 if word in stop_words]\n",
    "print(\"List of all the stopwords in corpus1\",set(stop_words_list))\n",
    "print(len(set(stop_words_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "99ee6fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Most Common Words without stopwords in Corpus 1:\n",
      "('money', 5484)\n",
      "('would', 4190)\n",
      "('bank', 3803)\n",
      "('one', 3796)\n",
      "('4', 3674)\n",
      "('new', 3071)\n",
      "('value', 2975)\n",
      "('may', 2944)\n",
      "('est', 2881)\n",
      "('gold', 2711)\n",
      "('stock', 2643)\n",
      "('great', 2344)\n",
      "('business', 2319)\n",
      "('time', 2282)\n",
      "('banks', 2204)\n",
      "('exchange', 2197)\n",
      "('project', 2169)\n",
      "('states', 2127)\n",
      "('made', 2061)\n",
      "('country', 1940)\n",
      "('upon', 1931)\n",
      "('market', 1916)\n",
      "('york', 1768)\n",
      "('work', 1753)\n",
      "('per', 1729)\n",
      "('much', 1697)\n",
      "('credit', 1672)\n",
      "('united', 1650)\n",
      "('years', 1560)\n",
      "('must', 1480)\n"
     ]
    }
   ],
   "source": [
    "# Get the 30 most common words\n",
    "top_30_words = stop_word_common_words(not_stop_words_list).most_common(30)\n",
    "\n",
    "# Print the 30 most common words\n",
    "print(\"30 Most Common Words without stopwords in Corpus 1:\")\n",
    "for word in top_30_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9f5908d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Common Words without stopwords in Corpus 1:\n",
      "('money', 5484)\n",
      "('would', 4190)\n",
      "('bank', 3803)\n",
      "('one', 3796)\n",
      "('4', 3674)\n",
      "('new', 3071)\n",
      "('value', 2975)\n",
      "('may', 2944)\n",
      "('est', 2881)\n",
      "('gold', 2711)\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common words\n",
    "top_10_words = stop_word_common_words(not_stop_words_list).most_common(10)\n",
    "\n",
    "# Print the 10 most common words\n",
    "print(\"10 Most Common Words without stopwords in Corpus 1:\")\n",
    "for word in top_10_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e57de49a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Most Common Words without stopwords in Corpus 1:\n",
      "('money', 5484)\n",
      "('would', 4190)\n",
      "('bank', 3803)\n",
      "('one', 3796)\n",
      "('4', 3674)\n",
      "('new', 3071)\n",
      "('value', 2975)\n",
      "('may', 2944)\n",
      "('est', 2881)\n",
      "('gold', 2711)\n",
      "('stock', 2643)\n",
      "('great', 2344)\n",
      "('business', 2319)\n",
      "('time', 2282)\n",
      "('banks', 2204)\n",
      "('exchange', 2197)\n",
      "('project', 2169)\n",
      "('states', 2127)\n",
      "('made', 2061)\n",
      "('country', 1940)\n",
      "('upon', 1931)\n",
      "('market', 1916)\n",
      "('york', 1768)\n",
      "('work', 1753)\n",
      "('per', 1729)\n",
      "('much', 1697)\n",
      "('credit', 1672)\n",
      "('united', 1650)\n",
      "('years', 1560)\n",
      "('must', 1480)\n",
      "('state', 1406)\n",
      "('many', 1400)\n",
      "('prices', 1363)\n",
      "('make', 1349)\n",
      "('every', 1345)\n",
      "('company', 1332)\n",
      "('year', 1328)\n",
      "('public', 1327)\n",
      "('large', 1323)\n",
      "('could', 1311)\n",
      "('amount', 1305)\n",
      "('two', 1295)\n",
      "('general', 1295)\n",
      "('cent', 1287)\n",
      "('first', 1271)\n",
      "('theory', 1271)\n",
      "('interest', 1263)\n",
      "('good', 1255)\n",
      "('capital', 1241)\n",
      "('silver', 1223)\n",
      "('government', 1175)\n",
      "('part', 1155)\n",
      "('street', 1151)\n",
      "('reserve', 1144)\n",
      "('price', 1126)\n",
      "('men', 1125)\n",
      "('without', 1104)\n",
      "('trade', 1103)\n",
      "('also', 1087)\n",
      "('use', 1079)\n",
      "('people', 1058)\n",
      "('even', 1047)\n",
      "('bonds', 1046)\n",
      "('way', 1037)\n",
      "('well', 1034)\n",
      "('man', 1032)\n",
      "('stocks', 1029)\n",
      "('banking', 1021)\n",
      "('notes', 1019)\n",
      "('said', 1016)\n",
      "('shall', 1007)\n",
      "('deposits', 975)\n",
      "('england', 970)\n",
      "('day', 963)\n",
      "('however', 962)\n",
      "('system', 949)\n",
      "('fact', 948)\n",
      "('case', 945)\n",
      "('1', 919)\n",
      "('national', 917)\n",
      "('us', 911)\n",
      "('present', 895)\n",
      "('world', 892)\n",
      "('works', 877)\n",
      "('house', 863)\n",
      "('see', 860)\n",
      "('paid', 854)\n",
      "('demand', 848)\n",
      "('less', 848)\n",
      "('power', 832)\n",
      "('pay', 831)\n",
      "('terms', 824)\n",
      "('wall', 824)\n",
      "('paper', 823)\n",
      "('banker', 809)\n",
      "('take', 802)\n",
      "('another', 794)\n",
      "('law', 794)\n",
      "('long', 787)\n",
      "('currency', 787)\n"
     ]
    }
   ],
   "source": [
    "# Get the 100 most common words\n",
    "top_100_words = stop_word_common_words(not_stop_words_list).most_common(100)\n",
    "\n",
    "# Print the 100 most common words\n",
    "print(\"100 Most Common Words without stopwords in Corpus 1:\")\n",
    "for word in top_100_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "afd6ce9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Most Common bigrams without stopwords in Corpus 1:\n",
      "(('4', 'est'), 2877)\n",
      "(('new', 'york'), 1752)\n",
      "(('united', 'states'), 1571)\n",
      "(('per', 'cent'), 1084)\n",
      "(('stock', 'exchange'), 836)\n",
      "(('wall', 'street'), 762)\n",
      "(('project', 'gutenberg'), 754)\n",
      "(('bank', 'england'), 473)\n",
      "(('value', 'money'), 464)\n",
      "(('project', 'electronic'), 432)\n",
      "(('clearing', 'house'), 392)\n",
      "(('electronic', 'works'), 384)\n",
      "(('quantity', 'theory'), 347)\n",
      "(('federal', 'reserve'), 326)\n",
      "(('gutenberg', 'literary'), 312)\n",
      "(('literary', 'archive'), 312)\n",
      "(('archive', 'foundation'), 300)\n",
      "(('trust', 'company'), 272)\n",
      "(('electronic', 'work'), 264)\n",
      "(('gold', 'silver'), 256)\n",
      "(('national', 'bank'), 242)\n",
      "(('set', 'forth'), 236)\n",
      "(('bank', 'notes'), 223)\n",
      "(('terms', 'agreement'), 217)\n",
      "(('san', 'francisco'), 207)\n",
      "(('money', 'market'), 201)\n",
      "(('legal', 'tender'), 200)\n",
      "(('paper', 'money'), 196)\n",
      "(('project', 'license'), 192)\n",
      "(('national', 'banks'), 186)\n"
     ]
    }
   ],
   "source": [
    "# Get the 30 most common bigrams\n",
    "top_30_words = stop_word_common_bigrams(not_stop_words_list).most_common(30)\n",
    "\n",
    "# Print the 30 most common bigrams\n",
    "print(\"30 Most Common bigrams without stopwords in Corpus 1:\")\n",
    "for word in top_30_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1052f7d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Most Common bigrams without stopwords in Corpus 1:\n",
      "(('4', 'est'), 2877)\n",
      "(('new', 'york'), 1752)\n",
      "(('united', 'states'), 1571)\n",
      "(('per', 'cent'), 1084)\n",
      "(('stock', 'exchange'), 836)\n",
      "(('wall', 'street'), 762)\n",
      "(('project', 'gutenberg'), 754)\n",
      "(('bank', 'england'), 473)\n",
      "(('value', 'money'), 464)\n",
      "(('project', 'electronic'), 432)\n",
      "(('clearing', 'house'), 392)\n",
      "(('electronic', 'works'), 384)\n",
      "(('quantity', 'theory'), 347)\n",
      "(('federal', 'reserve'), 326)\n",
      "(('gutenberg', 'literary'), 312)\n",
      "(('literary', 'archive'), 312)\n",
      "(('archive', 'foundation'), 300)\n",
      "(('trust', 'company'), 272)\n",
      "(('electronic', 'work'), 264)\n",
      "(('gold', 'silver'), 256)\n",
      "(('national', 'bank'), 242)\n",
      "(('set', 'forth'), 236)\n",
      "(('bank', 'notes'), 223)\n",
      "(('terms', 'agreement'), 217)\n",
      "(('san', 'francisco'), 207)\n",
      "(('money', 'market'), 201)\n",
      "(('legal', 'tender'), 200)\n",
      "(('paper', 'money'), 196)\n",
      "(('project', 'license'), 192)\n",
      "(('national', 'banks'), 186)\n",
      "(('reserve', 'bank'), 177)\n",
      "(('rate', 'interest'), 174)\n",
      "(('full', 'project'), 168)\n",
      "(('million', 'dollars'), 162)\n",
      "(('york', 'stock'), 159)\n",
      "(('supply', 'demand'), 152)\n",
      "(('mr', 'merchant'), 152)\n",
      "(('uncle', 'sam'), 147)\n",
      "(('foreign', 'exchange'), 145)\n",
      "(('let', 'us'), 143)\n",
      "(('1911', '1910'), 142)\n",
      "(('stock', 'market'), 141)\n",
      "(('york', 'city'), 141)\n",
      "(('1913', '1912'), 141)\n",
      "(('1912', '1911'), 141)\n",
      "(('1910', '1909'), 141)\n",
      "(('1916', '1915'), 140)\n",
      "(('1902', '1901'), 140)\n",
      "(('years', 'ago'), 139)\n",
      "(('real', 'estate'), 139)\n",
      "(('1898', '1897'), 139)\n",
      "(('1900', '1899'), 139)\n",
      "(('1903', '1902'), 139)\n",
      "(('1907', '1906'), 139)\n",
      "(('1989', '1988'), 139)\n",
      "(('1988', '1987'), 139)\n",
      "(('1987', '1986'), 139)\n",
      "(('1986', '1985'), 139)\n",
      "(('1985', '1984'), 139)\n",
      "(('1984', '1983'), 139)\n",
      "(('1993', '4'), 138)\n",
      "(('1983', '1982'), 138)\n",
      "(('1982', '1981'), 138)\n",
      "(('1981', '1980'), 138)\n",
      "(('1980', '1979'), 138)\n",
      "(('1979', '1978'), 138)\n",
      "(('1978', '1977'), 138)\n",
      "(('1977', '1976'), 138)\n",
      "(('1976', '1975'), 138)\n",
      "(('1975', '1974'), 138)\n",
      "(('1974', '1973'), 138)\n",
      "(('1973', '1972'), 138)\n",
      "(('1972', '1971'), 138)\n",
      "(('1971', '1970'), 138)\n",
      "(('1970', '1969'), 138)\n",
      "(('1969', '1968'), 138)\n",
      "(('1968', '1967'), 138)\n",
      "(('1967', '1966'), 138)\n",
      "(('1966', '1965'), 138)\n",
      "(('1965', '1964'), 138)\n",
      "(('1964', '1963'), 138)\n",
      "(('1963', '1962'), 138)\n",
      "(('1962', '1961'), 138)\n",
      "(('1961', '1960'), 138)\n",
      "(('1960', '1959'), 138)\n",
      "(('1959', '1958'), 138)\n",
      "(('1958', '1957'), 138)\n",
      "(('1957', '1956'), 138)\n",
      "(('1956', '1955'), 138)\n",
      "(('1955', '1954'), 138)\n",
      "(('1954', '1953'), 138)\n",
      "(('1953', '1952'), 138)\n",
      "(('1952', '1951'), 138)\n",
      "(('1951', '1950'), 138)\n",
      "(('1950', '1949'), 138)\n",
      "(('1949', '1948'), 138)\n",
      "(('1948', '1947'), 138)\n",
      "(('1947', '1946'), 138)\n",
      "(('1946', '1945'), 138)\n",
      "(('1945', '1944'), 138)\n"
     ]
    }
   ],
   "source": [
    "# Get the 100 most common bigrams\n",
    "top_100_words = stop_word_common_bigrams(not_stop_words_list).most_common(100)\n",
    "\n",
    "# Print the 100 most common bigrams\n",
    "print(\"100 Most Common bigrams without stopwords in Corpus 1:\")\n",
    "for word in top_100_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cfc10fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Common bigrams without stopwords in Corpus 1:\n",
      "(('4', 'est'), 2877)\n",
      "(('new', 'york'), 1752)\n",
      "(('united', 'states'), 1571)\n",
      "(('per', 'cent'), 1084)\n",
      "(('stock', 'exchange'), 836)\n",
      "(('wall', 'street'), 762)\n",
      "(('project', 'gutenberg'), 754)\n",
      "(('bank', 'england'), 473)\n",
      "(('value', 'money'), 464)\n",
      "(('project', 'electronic'), 432)\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common bigrams\n",
    "top_10_words = stop_word_common_bigrams(not_stop_words_list).most_common(10)\n",
    "\n",
    "# Print the 10 most common bigrams\n",
    "print(\"10 Most Common bigrams without stopwords in Corpus 1:\")\n",
    "for word in top_10_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df78c4c",
   "metadata": {},
   "source": [
    "### Q4) You will need to preprocess the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0135b1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mukes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "import re\n",
    "\n",
    "# this has all the texts without puncuations marks and all alphanumeric texts\n",
    "preprocessed_text = tokenized_words_corpus1\n",
    "\n",
    "#remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "preprocessed_text = [word for word in preprocessed_text if word not in stop_words]\n",
    "\n",
    "#remove special headers, tags and codes\n",
    "preprocessed_text = [re.sub(r'\\[.*?\\]', '', word) for word in preprocessed_text]\n",
    "\n",
    "#remove short words\n",
    "preprocessed_text = [word for word in preprocessed_text if len(word) > 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2616bde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('money', 5484),\n",
       " ('would', 4190),\n",
       " ('bank', 3803),\n",
       " ('one', 3796),\n",
       " ('new', 3071),\n",
       " ('value', 2975),\n",
       " ('may', 2944),\n",
       " ('est', 2881),\n",
       " ('gold', 2711),\n",
       " ('stock', 2643),\n",
       " ('great', 2344),\n",
       " ('business', 2319),\n",
       " ('time', 2282),\n",
       " ('banks', 2204),\n",
       " ('exchange', 2197),\n",
       " ('project', 2169),\n",
       " ('states', 2127),\n",
       " ('made', 2061),\n",
       " ('country', 1940),\n",
       " ('upon', 1931),\n",
       " ('market', 1916),\n",
       " ('york', 1768),\n",
       " ('work', 1753),\n",
       " ('per', 1729),\n",
       " ('much', 1697),\n",
       " ('credit', 1672),\n",
       " ('united', 1650),\n",
       " ('years', 1560),\n",
       " ('must', 1480),\n",
       " ('state', 1406)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 30 most common words after preprossing \n",
    "top_30_words = most_common_words(preprocessed_text).most_common(30)\n",
    "top_30_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9c55d",
   "metadata": {},
   "source": [
    "# Corpus 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0f37414e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Corpus2\\\\1322-0.txt', 'Corpus2\\\\19002-0.txt', 'Corpus2\\\\2413-0.txt', 'Corpus2\\\\2638-0.txt', 'Corpus2\\\\29019-0.txt', 'Corpus2\\\\35-0.txt', 'Corpus2\\\\5200-0.txt', 'Corpus2\\\\pg1399.txt', 'Corpus2\\\\pg145.txt', 'Corpus2\\\\pg14838.txt', 'Corpus2\\\\pg1513.txt', 'Corpus2\\\\pg164.txt', 'Corpus2\\\\pg20796.txt', 'Corpus2\\\\pg24104.txt', 'Corpus2\\\\pg25344.txt', 'Corpus2\\\\pg32154.txt', 'Corpus2\\\\pg345.txt', 'Corpus2\\\\pg35997.txt', 'Corpus2\\\\pg42671.txt', 'Corpus2\\\\pg552.txt', 'Corpus2\\\\pg67979.txt', 'Corpus2\\\\pg76.txt', 'Corpus2\\\\pg768.txt', 'Corpus2\\\\pg8655.txt']\n"
     ]
    }
   ],
   "source": [
    "corpus1_dir = 'Corpus2'\n",
    "\n",
    "text_files = []\n",
    "\n",
    "for filename in os.listdir(str(os.getcwd())+'/'+corpus1_dir+'/'):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(corpus1_dir, filename)\n",
    "\n",
    "        text_files.append(file_path)\n",
    "\n",
    "\n",
    "print(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fe8449d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words():\n",
    "    lst = []\n",
    "    for file_path in text_files:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            words = word_tokenize(text)\n",
    "            words = [word.lower() for word in words if word.isalnum()]\n",
    "            lst.extend(words)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "17e2489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_words(lst):\n",
    "    word_counter = Counter()\n",
    "    word_counter.update(lst)\n",
    "    return word_counter\n",
    "\n",
    "def most_common_bigrams(lst):\n",
    "    bigram_counter = Counter()\n",
    "    bi_grams = list(ngrams(lst, 2))\n",
    "    bigram_counter.update(bi_grams)\n",
    "    return bigram_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6f69d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Most Common Words in Corpus 2:\n",
      "('the', 126172)\n",
      "('and', 84471)\n",
      "('to', 65979)\n",
      "('of', 64658)\n",
      "('a', 47553)\n",
      "('i', 44511)\n",
      "('in', 37030)\n",
      "('he', 35860)\n",
      "('that', 30940)\n",
      "('was', 29563)\n",
      "('it', 28776)\n",
      "('you', 25082)\n",
      "('his', 24536)\n",
      "('her', 22643)\n",
      "('with', 21929)\n",
      "('not', 19767)\n",
      "('she', 19523)\n",
      "('had', 19369)\n",
      "('for', 18796)\n",
      "('as', 17429)\n",
      "('but', 16564)\n",
      "('at', 16094)\n",
      "('on', 15108)\n",
      "('him', 14903)\n",
      "('is', 14599)\n",
      "('be', 13389)\n",
      "('s', 12931)\n",
      "('my', 12326)\n",
      "('me', 12304)\n",
      "('all', 12291)\n"
     ]
    }
   ],
   "source": [
    "tokenized_words_corpus2 = tokenize_words()\n",
    "\n",
    "# Get the 30 most common words\n",
    "top_30_words = most_common_words(tokenized_words_corpus2).most_common(30)\n",
    "\n",
    "# Print the 30 most common words\n",
    "print(\"30 Most Common Words in Corpus 2:\")\n",
    "for word in top_30_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "951f6cf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Most Common Words in Corpus 2:\n",
      "('the', 126172)\n",
      "('and', 84471)\n",
      "('to', 65979)\n",
      "('of', 64658)\n",
      "('a', 47553)\n",
      "('i', 44511)\n",
      "('in', 37030)\n",
      "('he', 35860)\n",
      "('that', 30940)\n",
      "('was', 29563)\n",
      "('it', 28776)\n",
      "('you', 25082)\n",
      "('his', 24536)\n",
      "('her', 22643)\n",
      "('with', 21929)\n",
      "('not', 19767)\n",
      "('she', 19523)\n",
      "('had', 19369)\n",
      "('for', 18796)\n",
      "('as', 17429)\n",
      "('but', 16564)\n",
      "('at', 16094)\n",
      "('on', 15108)\n",
      "('him', 14903)\n",
      "('is', 14599)\n",
      "('be', 13389)\n",
      "('s', 12931)\n",
      "('my', 12326)\n",
      "('me', 12304)\n",
      "('all', 12291)\n",
      "('said', 11859)\n",
      "('have', 11313)\n",
      "('this', 11006)\n",
      "('so', 9907)\n",
      "('they', 9290)\n",
      "('by', 9153)\n",
      "('from', 9115)\n",
      "('what', 8587)\n",
      "('or', 8052)\n",
      "('which', 7989)\n",
      "('there', 7974)\n",
      "('we', 7907)\n",
      "('no', 7724)\n",
      "('would', 7497)\n",
      "('were', 7410)\n",
      "('one', 7392)\n",
      "('if', 7126)\n",
      "('when', 6949)\n",
      "('t', 6857)\n",
      "('up', 6712)\n",
      "('out', 6701)\n",
      "('them', 6341)\n",
      "('are', 6275)\n",
      "('an', 6166)\n",
      "('do', 5940)\n",
      "('then', 5868)\n",
      "('could', 5846)\n",
      "('been', 5801)\n",
      "('will', 5598)\n",
      "('who', 5304)\n",
      "('more', 4941)\n",
      "('now', 4924)\n",
      "('your', 4902)\n",
      "('their', 4750)\n",
      "('about', 4729)\n",
      "('can', 4681)\n",
      "('did', 4483)\n",
      "('into', 4386)\n",
      "('see', 4312)\n",
      "('some', 4261)\n",
      "('any', 4163)\n",
      "('like', 4148)\n",
      "('very', 4147)\n",
      "('know', 4118)\n",
      "('man', 3998)\n",
      "('time', 3867)\n",
      "('little', 3786)\n",
      "('come', 3727)\n",
      "('how', 3725)\n",
      "('than', 3718)\n",
      "('down', 3542)\n",
      "('before', 3526)\n",
      "('only', 3523)\n",
      "('must', 3504)\n",
      "('well', 3451)\n",
      "('go', 3396)\n",
      "('over', 3278)\n",
      "('other', 3257)\n",
      "('never', 3131)\n",
      "('went', 3125)\n",
      "('has', 3103)\n",
      "('after', 3083)\n",
      "('am', 2940)\n",
      "('came', 2875)\n",
      "('good', 2870)\n",
      "('should', 2855)\n",
      "('such', 2852)\n",
      "('himself', 2852)\n",
      "('us', 2846)\n",
      "('old', 2818)\n"
     ]
    }
   ],
   "source": [
    "# Get the 100 most common words\n",
    "top_100_words = most_common_words(tokenized_words_corpus2).most_common(100)\n",
    "\n",
    "# Print the 100 most common words\n",
    "print(\"100 Most Common Words in Corpus 2:\")\n",
    "for word in top_100_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "30155e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Common Words in Corpus 2:\n",
      "('the', 126172)\n",
      "('and', 84471)\n",
      "('to', 65979)\n",
      "('of', 64658)\n",
      "('a', 47553)\n",
      "('i', 44511)\n",
      "('in', 37030)\n",
      "('he', 35860)\n",
      "('that', 30940)\n",
      "('was', 29563)\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common words\n",
    "top_10_words = most_common_words(tokenized_words_corpus2).most_common(10)\n",
    "\n",
    "# Print the 10 most common words\n",
    "print(\"10 Most Common Words in Corpus 2:\")\n",
    "for word in top_10_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d89ea40",
   "metadata": {},
   "source": [
    "### Q2 Repeat exercise 1 above but now do it for n-grams with n = 2 (bi-grams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cff4fed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Most Common bi-grams in Corpus 2:\n",
      "(('of', 'the'), 14411)\n",
      "(('in', 'the'), 9968)\n",
      "(('to', 'the'), 6803)\n",
      "(('and', 'the'), 4995)\n",
      "(('on', 'the'), 4725)\n",
      "(('it', 'was'), 4239)\n",
      "(('to', 'be'), 4083)\n",
      "(('at', 'the'), 3926)\n",
      "(('he', 'had'), 3820)\n",
      "(('he', 'was'), 3615)\n",
      "(('with', 'the'), 3101)\n",
      "(('and', 'i'), 2990)\n",
      "(('in', 'a'), 2984)\n",
      "(('of', 'his'), 2857)\n",
      "(('of', 'a'), 2779)\n",
      "(('that', 'he'), 2760)\n",
      "(('for', 'the'), 2742)\n",
      "(('it', 'is'), 2655)\n",
      "(('with', 'a'), 2626)\n",
      "(('i', 'am'), 2585)\n",
      "(('from', 'the'), 2571)\n",
      "(('had', 'been'), 2457)\n",
      "(('did', 'not'), 2346)\n",
      "(('i', 'have'), 2318)\n",
      "(('by', 'the'), 2243)\n",
      "(('all', 'the'), 2177)\n",
      "(('was', 'a'), 2164)\n",
      "(('don', 't'), 2157)\n",
      "(('and', 'he'), 2122)\n",
      "(('she', 'was'), 2108)\n"
     ]
    }
   ],
   "source": [
    "# Get the 30 most common words for ngram with n = 2\n",
    "top_30_words = most_common_bigrams(tokenized_words_corpus2).most_common(30)\n",
    "\n",
    "# Print the 30 most common words\n",
    "print(\"30 Most Common bi-grams in Corpus 2:\")\n",
    "for word in top_30_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c8a7cc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Most Common bi-grams in Corpus 2:\n",
      "(('of', 'the'), 14411)\n",
      "(('in', 'the'), 9968)\n",
      "(('to', 'the'), 6803)\n",
      "(('and', 'the'), 4995)\n",
      "(('on', 'the'), 4725)\n",
      "(('it', 'was'), 4239)\n",
      "(('to', 'be'), 4083)\n",
      "(('at', 'the'), 3926)\n",
      "(('he', 'had'), 3820)\n",
      "(('he', 'was'), 3615)\n",
      "(('with', 'the'), 3101)\n",
      "(('and', 'i'), 2990)\n",
      "(('in', 'a'), 2984)\n",
      "(('of', 'his'), 2857)\n",
      "(('of', 'a'), 2779)\n",
      "(('that', 'he'), 2760)\n",
      "(('for', 'the'), 2742)\n",
      "(('it', 'is'), 2655)\n",
      "(('with', 'a'), 2626)\n",
      "(('i', 'am'), 2585)\n",
      "(('from', 'the'), 2571)\n",
      "(('had', 'been'), 2457)\n",
      "(('did', 'not'), 2346)\n",
      "(('i', 'have'), 2318)\n",
      "(('by', 'the'), 2243)\n",
      "(('all', 'the'), 2177)\n",
      "(('was', 'a'), 2164)\n",
      "(('don', 't'), 2157)\n",
      "(('and', 'he'), 2122)\n",
      "(('she', 'was'), 2108)\n",
      "(('she', 'had'), 2099)\n",
      "(('in', 'his'), 2085)\n",
      "(('that', 'i'), 2008)\n",
      "(('of', 'her'), 1983)\n",
      "(('to', 'her'), 1959)\n",
      "(('out', 'of'), 1912)\n",
      "(('there', 'was'), 1888)\n",
      "(('i', 'was'), 1887)\n",
      "(('that', 'the'), 1805)\n",
      "(('he', 'said'), 1776)\n",
      "(('to', 'him'), 1768)\n",
      "(('into', 'the'), 1718)\n",
      "(('could', 'not'), 1707)\n",
      "(('to', 'me'), 1665)\n",
      "(('but', 'i'), 1610)\n",
      "(('for', 'a'), 1605)\n",
      "(('him', 'and'), 1574)\n",
      "(('you', 'are'), 1545)\n",
      "(('the', 'prince'), 1537)\n",
      "(('the', 'same'), 1505)\n",
      "(('a', 'little'), 1501)\n",
      "(('that', 'she'), 1475)\n",
      "(('as', 'he'), 1451)\n",
      "(('if', 'you'), 1431)\n",
      "(('was', 'not'), 1426)\n",
      "(('it', 's'), 1360)\n",
      "(('have', 'been'), 1350)\n",
      "(('to', 'his'), 1345)\n",
      "(('and', 'then'), 1339)\n",
      "(('to', 'see'), 1337)\n",
      "(('i', 'can'), 1327)\n",
      "(('one', 'of'), 1295)\n",
      "(('and', 'that'), 1289)\n",
      "(('was', 'the'), 1289)\n",
      "(('of', 'this'), 1276)\n",
      "(('i', 'had'), 1264)\n",
      "(('would', 'have'), 1252)\n",
      "(('and', 'she'), 1249)\n",
      "(('in', 'her'), 1245)\n",
      "(('and', 'a'), 1240)\n",
      "(('to', 'do'), 1205)\n",
      "(('would', 'be'), 1201)\n",
      "(('when', 'he'), 1165)\n",
      "(('with', 'his'), 1157)\n",
      "(('of', 'my'), 1127)\n",
      "(('but', 'he'), 1114)\n",
      "(('a', 'man'), 1111)\n",
      "(('him', 'to'), 1109)\n",
      "(('they', 'were'), 1105)\n",
      "(('as', 'a'), 1096)\n",
      "(('is', 'a'), 1095)\n",
      "(('said', 'the'), 1091)\n",
      "(('but', 'the'), 1091)\n",
      "(('he', 'could'), 1089)\n",
      "(('of', 'it'), 1087)\n",
      "(('do', 'you'), 1084)\n",
      "(('he', 'would'), 1078)\n",
      "(('do', 'not'), 1077)\n",
      "(('to', 'a'), 1073)\n",
      "(('i', 'could'), 1071)\n",
      "(('said', 'to'), 1069)\n",
      "(('i', 'shall'), 1059)\n",
      "(('she', 'said'), 1048)\n",
      "(('me', 'and'), 1044)\n",
      "(('the', 'other'), 1033)\n",
      "(('i', 'm'), 1031)\n",
      "(('the', 'first'), 1030)\n",
      "(('and', 'his'), 1030)\n",
      "(('seemed', 'to'), 1027)\n",
      "(('as', 'i'), 1017)\n"
     ]
    }
   ],
   "source": [
    "# Get the 100 most common words for ngram with n = 2\n",
    "top_100_words = most_common_bigrams(tokenized_words_corpus2).most_common(100)\n",
    "\n",
    "# Print the 100 most common words\n",
    "print(\"100 Most Common bi-grams in Corpus 2:\")\n",
    "for word in top_100_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bff45b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Common bi-grams in Corpus 2:\n",
      "(('of', 'the'), 14411)\n",
      "(('in', 'the'), 9968)\n",
      "(('to', 'the'), 6803)\n",
      "(('and', 'the'), 4995)\n",
      "(('on', 'the'), 4725)\n",
      "(('it', 'was'), 4239)\n",
      "(('to', 'be'), 4083)\n",
      "(('at', 'the'), 3926)\n",
      "(('he', 'had'), 3820)\n",
      "(('he', 'was'), 3615)\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common words for ngram with n = 2\n",
    "top_10_words = most_common_bigrams(tokenized_words_corpus2).most_common(10)\n",
    "\n",
    "# Print the 10 most common words\n",
    "print(\"10 Most Common bi-grams in Corpus 2:\")\n",
    "for word in top_10_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f52a3f",
   "metadata": {},
   "source": [
    "### Q3 Find a stop word list. Then remove all words in that stop list and repeat exercise 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a40e491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "not_stop_words_list = [word for word in tokenized_words_corpus2 if word not in stop_words]\n",
    "\n",
    "def stop_word_common_words(not_stop_words_list):\n",
    "    word_counter = Counter()\n",
    "    word_counter.update(not_stop_words_list)\n",
    "    return word_counter\n",
    "\n",
    "def stop_word_common_bigrams(not_stop_words_list):\n",
    "    bigram_counter = Counter()\n",
    "    bi_grams = list(ngrams(not_stop_words_list, 2))\n",
    "    bigram_counter.update(bi_grams)\n",
    "    return bigram_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a11c5a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all stop words in corpus2: \n",
      "{'these', 'about', 'ain', 'd', 'while', 'hasn', 'between', 'by', 'ourselves', 'you', 'own', 'isn', 'ma', 'was', 'yourselves', 'hers', 'other', 'their', 'our', 'why', 'for', 'further', 'so', 'during', 'before', 'myself', 'herself', 'which', 'my', 'or', 'had', 've', 'having', 'this', 'be', 'weren', 'whom', 'mightn', 'each', 'm', 'yourself', 'more', 'have', 'out', 'on', 'haven', 'too', 'over', 'its', 'in', 'any', 'wouldn', 'wasn', 'just', 'been', 'has', 'her', 'y', 'now', 'most', 'itself', 'as', 'once', 'won', 'your', 'a', 'few', 'does', 'above', 'yours', 'they', 'who', 'the', 'both', 'only', 'to', 'should', 'i', 'them', 'until', 'when', 'what', 'some', 'his', 'being', 'couldn', 'll', 'with', 'such', 'all', 'theirs', 'can', 'he', 'is', 'under', 'aren', 'don', 'after', 'here', 'than', 'did', 'o', 't', 'an', 'needn', 'shan', 'from', 'himself', 'doing', 'of', 'themselves', 'am', 'because', 'where', 'nor', 'him', 'against', 'then', 'up', 'hadn', 'will', 'same', 's', 'but', 'do', 'those', 'it', 'mustn', 're', 'are', 'there', 'if', 'very', 'that', 'we', 'were', 'and', 'she', 'through', 'me', 'off', 'down', 'didn', 'how', 'into', 'no', 'shouldn', 'below', 'doesn', 'again', 'not', 'at', 'ours'}\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "stop_words_list = [word for word in tokenized_words_corpus2 if word in stop_words]\n",
    "\n",
    "print('List of all stop words in corpus2: ')\n",
    "print(set(stop_words_list))\n",
    "print(len(set(stop_words_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a16f838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Most Common Words without stopwords in Corpus 2:\n",
      "('said', 11859)\n",
      "('would', 7497)\n",
      "('one', 7392)\n",
      "('could', 5846)\n",
      "('see', 4312)\n",
      "('like', 4148)\n",
      "('know', 4118)\n",
      "('man', 3998)\n",
      "('time', 3867)\n",
      "('little', 3786)\n",
      "('come', 3727)\n",
      "('must', 3504)\n",
      "('well', 3451)\n",
      "('go', 3396)\n",
      "('never', 3131)\n",
      "('went', 3125)\n",
      "('came', 2875)\n",
      "('good', 2870)\n",
      "('us', 2846)\n",
      "('old', 2818)\n",
      "('made', 2813)\n",
      "('much', 2712)\n",
      "('say', 2711)\n",
      "('back', 2578)\n",
      "('thought', 2575)\n",
      "('shall', 2544)\n",
      "('away', 2511)\n",
      "('may', 2507)\n",
      "('eyes', 2467)\n",
      "('think', 2463)\n"
     ]
    }
   ],
   "source": [
    "# Get the 30 most common words\n",
    "top_30_words = stop_word_common_words(not_stop_words_list).most_common(30)\n",
    "\n",
    "# Print the 30 most common words\n",
    "print(\"30 Most Common Words without stopwords in Corpus 2:\")\n",
    "for word in top_30_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d2faa136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Common Words without stopwords in Corpus 2:\n",
      "('said', 11859)\n",
      "('would', 7497)\n",
      "('one', 7392)\n",
      "('could', 5846)\n",
      "('see', 4312)\n",
      "('like', 4148)\n",
      "('know', 4118)\n",
      "('man', 3998)\n",
      "('time', 3867)\n",
      "('little', 3786)\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common words\n",
    "top_10_words = stop_word_common_words(not_stop_words_list).most_common(10)\n",
    "\n",
    "# Print the 10 most common words\n",
    "print(\"10 Most Common Words without stopwords in Corpus 2:\")\n",
    "for word in top_10_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "eafb2576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Most Common Words without stopwords in Corpus 2:\n",
      "('said', 11859)\n",
      "('would', 7497)\n",
      "('one', 7392)\n",
      "('could', 5846)\n",
      "('see', 4312)\n",
      "('like', 4148)\n",
      "('know', 4118)\n",
      "('man', 3998)\n",
      "('time', 3867)\n",
      "('little', 3786)\n",
      "('come', 3727)\n",
      "('must', 3504)\n",
      "('well', 3451)\n",
      "('go', 3396)\n",
      "('never', 3131)\n",
      "('went', 3125)\n",
      "('came', 2875)\n",
      "('good', 2870)\n",
      "('us', 2846)\n",
      "('old', 2818)\n",
      "('made', 2813)\n",
      "('much', 2712)\n",
      "('say', 2711)\n",
      "('back', 2578)\n",
      "('thought', 2575)\n",
      "('shall', 2544)\n",
      "('away', 2511)\n",
      "('may', 2507)\n",
      "('eyes', 2467)\n",
      "('think', 2463)\n",
      "('nothing', 2455)\n",
      "('long', 2441)\n",
      "('without', 2404)\n",
      "('two', 2358)\n",
      "('day', 2354)\n",
      "('even', 2339)\n",
      "('might', 2304)\n",
      "('way', 2265)\n",
      "('life', 2231)\n",
      "('work', 2209)\n",
      "('make', 2190)\n",
      "('first', 2147)\n",
      "('though', 2144)\n",
      "('project', 2143)\n",
      "('prince', 2136)\n",
      "('saw', 2109)\n",
      "('face', 2103)\n",
      "('hand', 2085)\n",
      "('upon', 2037)\n",
      "('great', 1993)\n",
      "('still', 1969)\n",
      "('last', 1968)\n",
      "('tell', 1936)\n",
      "('seemed', 1924)\n",
      "('look', 1908)\n",
      "('thou', 1892)\n",
      "('looked', 1892)\n",
      "('take', 1883)\n",
      "('took', 1881)\n",
      "('let', 1874)\n",
      "('get', 1873)\n",
      "('love', 1855)\n",
      "('got', 1844)\n",
      "('felt', 1839)\n",
      "('every', 1789)\n",
      "('something', 1789)\n",
      "('going', 1757)\n",
      "('head', 1745)\n",
      "('yet', 1732)\n",
      "('always', 1722)\n",
      "('people', 1696)\n",
      "('room', 1652)\n",
      "('night', 1648)\n",
      "('put', 1643)\n",
      "('right', 1643)\n",
      "('house', 1638)\n",
      "('young', 1611)\n",
      "('levin', 1608)\n",
      "('thee', 1607)\n",
      "('give', 1600)\n",
      "('heard', 1571)\n",
      "('ever', 1568)\n",
      "('men', 1562)\n",
      "('oh', 1559)\n",
      "('thing', 1550)\n",
      "('mother', 1531)\n",
      "('told', 1503)\n",
      "('another', 1500)\n",
      "('till', 1488)\n",
      "('new', 1470)\n",
      "('yes', 1470)\n",
      "('knew', 1450)\n",
      "('asked', 1447)\n",
      "('left', 1446)\n",
      "('quite', 1446)\n",
      "('heart', 1436)\n",
      "('things', 1426)\n",
      "('found', 1419)\n",
      "('mind', 1416)\n",
      "('done', 1386)\n"
     ]
    }
   ],
   "source": [
    "# Get the 100 most common words\n",
    "top_100_words = stop_word_common_words(not_stop_words_list).most_common(100)\n",
    "\n",
    "# Print the 100 most common words\n",
    "print(\"100 Most Common Words without stopwords in Corpus 2:\")\n",
    "for word in top_100_words:\n",
    "    print(word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "df8b4be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Most Common bigrams without stopwords in Corpus 2:\n",
      "(('project', 'gutenberg'), 743)\n",
      "(('alexey', 'alexandrovitch'), 570)\n",
      "(('stepan', 'arkadyevitch'), 547)\n",
      "(('project', 'electronic'), 432)\n",
      "(('electronic', 'works'), 384)\n",
      "(('captain', 'nemo'), 383)\n",
      "(('old', 'man'), 373)\n",
      "(('could', 'see'), 360)\n",
      "(('united', 'states'), 359)\n",
      "(('van', 'helsing'), 315)\n",
      "(('gutenberg', 'literary'), 312)\n",
      "(('literary', 'archive'), 312)\n",
      "(('archive', 'foundation'), 302)\n",
      "(('sergey', 'ivanovitch'), 290)\n",
      "(('young', 'man'), 275)\n",
      "(('electronic', 'work'), 264)\n",
      "(('let', 'us'), 258)\n",
      "(('nastasia', 'philipovna'), 239)\n",
      "(('sir', 'james'), 239)\n",
      "(('one', 'day'), 230)\n",
      "(('said', 'dorothea'), 227)\n",
      "(('first', 'time'), 220)\n",
      "(('next', 'day'), 218)\n",
      "(('terms', 'agreement'), 216)\n",
      "(('darya', 'alexandrovna'), 204)\n",
      "(('set', 'forth'), 203)\n",
      "(('one', 'another'), 198)\n",
      "(('said', 'prince'), 196)\n",
      "(('ned', 'land'), 196)\n",
      "(('project', 'license'), 192)\n"
     ]
    }
   ],
   "source": [
    "# Get the 30 most common bigrams\n",
    "top_30_words = stop_word_common_bigrams(not_stop_words_list).most_common(30)\n",
    "\n",
    "# Print the 30 most common bigrams\n",
    "print(\"30 Most Common bigrams without stopwords in Corpus 2:\")\n",
    "for word in top_30_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "359a39f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Most Common bigrams without stopwords in Corpus 2:\n",
      "(('project', 'gutenberg'), 743)\n",
      "(('alexey', 'alexandrovitch'), 570)\n",
      "(('stepan', 'arkadyevitch'), 547)\n",
      "(('project', 'electronic'), 432)\n",
      "(('electronic', 'works'), 384)\n",
      "(('captain', 'nemo'), 383)\n",
      "(('old', 'man'), 373)\n",
      "(('could', 'see'), 360)\n",
      "(('united', 'states'), 359)\n",
      "(('van', 'helsing'), 315)\n",
      "(('gutenberg', 'literary'), 312)\n",
      "(('literary', 'archive'), 312)\n",
      "(('archive', 'foundation'), 302)\n",
      "(('sergey', 'ivanovitch'), 290)\n",
      "(('young', 'man'), 275)\n",
      "(('electronic', 'work'), 264)\n",
      "(('let', 'us'), 258)\n",
      "(('nastasia', 'philipovna'), 239)\n",
      "(('sir', 'james'), 239)\n",
      "(('one', 'day'), 230)\n",
      "(('said', 'dorothea'), 227)\n",
      "(('first', 'time'), 220)\n",
      "(('next', 'day'), 218)\n",
      "(('terms', 'agreement'), 216)\n",
      "(('darya', 'alexandrovna'), 204)\n",
      "(('set', 'forth'), 203)\n",
      "(('one', 'another'), 198)\n",
      "(('said', 'prince'), 196)\n",
      "(('ned', 'land'), 196)\n",
      "(('project', 'license'), 192)\n",
      "(('come', 'back'), 185)\n",
      "(('great', 'deal'), 182)\n",
      "(('said', 'levin'), 176)\n",
      "(('let', 'go'), 169)\n",
      "(('full', 'project'), 168)\n",
      "(('lizabetha', 'prokofievna'), 167)\n",
      "(('thou', 'art'), 162)\n",
      "(('went', 'away'), 160)\n",
      "(('hester', 'prynne'), 157)\n",
      "(('evgenie', 'pavlovitch'), 155)\n",
      "(('go', 'away'), 153)\n",
      "(('one', 'thing'), 152)\n",
      "(('came', 'back'), 151)\n",
      "(('must', 'go'), 150)\n",
      "(('every', 'day'), 145)\n",
      "(('one', 'side'), 144)\n",
      "(('thou', 'hast'), 144)\n",
      "(('young', 'lady'), 144)\n",
      "(('would', 'never'), 144)\n",
      "(('could', 'help'), 143)\n",
      "(('last', 'night'), 142)\n",
      "(('would', 'like'), 141)\n",
      "(('would', 'come'), 140)\n",
      "(('said', 'lydgate'), 138)\n",
      "(('two', 'three'), 135)\n",
      "(('would', 'go'), 134)\n",
      "(('said', 'valancy'), 132)\n",
      "(('one', 'could'), 130)\n",
      "(('said', 'nothing'), 129)\n",
      "(('long', 'time'), 128)\n",
      "(('said', 'stepan'), 127)\n",
      "(('every', 'one'), 126)\n",
      "(('three', 'days'), 121)\n",
      "(('half', 'hour'), 120)\n",
      "(('project', 'works'), 120)\n",
      "(('project', 'work'), 120)\n",
      "(('madame', 'bovary'), 120)\n",
      "(('long', 'ago'), 119)\n",
      "(('uncle', 'benjamin'), 118)\n",
      "(('never', 'seen'), 117)\n",
      "(('good', 'deal'), 117)\n",
      "(('would', 'make'), 117)\n",
      "(('one', 'would'), 116)\n",
      "(('yes', 'said'), 116)\n",
      "(('lady', 'catherine'), 113)\n",
      "(('go', 'back'), 111)\n",
      "(('could', 'hear'), 110)\n",
      "(('would', 'take'), 107)\n",
      "(('following', 'verses'), 107)\n",
      "(('protected', 'copyright'), 106)\n",
      "(('copyright', 'law'), 106)\n",
      "(('could', 'hardly'), 106)\n",
      "(('said', 'would'), 106)\n",
      "(('lidia', 'ivanovna'), 106)\n",
      "(('said', 'rosamond'), 106)\n",
      "(('scarlet', 'letter'), 105)\n",
      "(('know', 'said'), 104)\n",
      "(('young', 'men'), 103)\n",
      "(('one', 'else'), 103)\n",
      "(('would', 'say'), 103)\n",
      "(('thou', 'wilt'), 103)\n",
      "(('made', 'mind'), 102)\n",
      "(('could', 'get'), 102)\n",
      "(('dare', 'say'), 102)\n",
      "(('well', 'said'), 101)\n",
      "(('cousin', 'stickles'), 101)\n",
      "(('shall', 'go'), 100)\n",
      "(('thee', 'thou'), 100)\n",
      "(('could', 'make'), 99)\n",
      "(('next', 'morning'), 99)\n"
     ]
    }
   ],
   "source": [
    "# Get the 100 most common bigrams\n",
    "top_100_words = stop_word_common_bigrams(not_stop_words_list).most_common(100)\n",
    "\n",
    "# Print the 100 most common bigrams\n",
    "print(\"100 Most Common bigrams without stopwords in Corpus 2:\")\n",
    "for word in top_100_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b19e7521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Common bigrams without stopwords in Corpus 2:\n",
      "(('project', 'gutenberg'), 743)\n",
      "(('alexey', 'alexandrovitch'), 570)\n",
      "(('stepan', 'arkadyevitch'), 547)\n",
      "(('project', 'electronic'), 432)\n",
      "(('electronic', 'works'), 384)\n",
      "(('captain', 'nemo'), 383)\n",
      "(('old', 'man'), 373)\n",
      "(('could', 'see'), 360)\n",
      "(('united', 'states'), 359)\n",
      "(('van', 'helsing'), 315)\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common bigrams\n",
    "top_10_words = stop_word_common_bigrams(not_stop_words_list).most_common(10)\n",
    "\n",
    "# Print the 10 most common bigrams\n",
    "print(\"10 Most Common bigrams without stopwords in Corpus 2:\")\n",
    "for word in top_10_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e44c49",
   "metadata": {},
   "source": [
    "### Q4) You will need to preprocess the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "98c4bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mukes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "import re\n",
    "\n",
    "# this has all the texts without puncuations marks and all alphanumeric texts\n",
    "preprocessed_text = tokenized_words_corpus2\n",
    "\n",
    "#remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "preprocessed_text = [word for word in preprocessed_text if word not in stop_words]\n",
    "\n",
    "#remove special headers, tags and codes\n",
    "preprocessed_text = [re.sub(r'\\[.*?\\]', '', word) for word in preprocessed_text]\n",
    "\n",
    "#remove short words\n",
    "preprocessed_text = [word for word in preprocessed_text if len(word) > 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "435bb0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 11859),\n",
       " ('would', 7497),\n",
       " ('one', 7392),\n",
       " ('could', 5846),\n",
       " ('see', 4312),\n",
       " ('like', 4148),\n",
       " ('know', 4118),\n",
       " ('man', 3998),\n",
       " ('time', 3867),\n",
       " ('little', 3786),\n",
       " ('come', 3727),\n",
       " ('must', 3504),\n",
       " ('well', 3451),\n",
       " ('never', 3131),\n",
       " ('went', 3125),\n",
       " ('came', 2875),\n",
       " ('good', 2870),\n",
       " ('old', 2818),\n",
       " ('made', 2813),\n",
       " ('much', 2712),\n",
       " ('say', 2711),\n",
       " ('back', 2578),\n",
       " ('thought', 2575),\n",
       " ('shall', 2544),\n",
       " ('away', 2511),\n",
       " ('may', 2507),\n",
       " ('eyes', 2467),\n",
       " ('think', 2463),\n",
       " ('nothing', 2455),\n",
       " ('long', 2441)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 30 most common words after preprossing \n",
    "top_30_words = most_common_words(preprocessed_text).most_common(30)\n",
    "top_30_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
